{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EinfÃ¼hrung in Large Language Models (LLMs)
",
    "**Thema:** Textgenerierung mit GPT-2  
",
    "**Autor:** [Dein Name]  
",
    "**Ziel:** Erste Experimente mit einem vortrainierten Large Language Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ› ï¸ Setup
",
    "!pip install transformers torch --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline
",
    "
",
    "# ğŸ“¦ Modell laden
",
    "generator = pipeline("text-generation", model="gpt2")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ“ Erster Versuch
",
    "prompt = "Die Erde ist ein"
",
    "result = generator(prompt, max_length=20, num_return_sequences=1)
",
    "
",
    "print("ğŸ”® Generierter Text:")
",
    "print(result[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ¯ Interaktive Aufgabe
",
    "# Ã„ndere den Prompt und max_length und sieh, wie sich der Output verÃ¤ndert.
",
    "
",
    "prompt = "KÃ¼nstliche Intelligenz wird in Zukunft"
",
    "result = generator(prompt, max_length=30, num_return_sequences=2)
",
    "
",
    "print("\nğŸ§ª Experiment:")
",
    "for i, r in enumerate(result):
",
    "    print(f"Version {i+1}:\n{r['generated_text']}\n")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ§ª Mit Sampling spielen
",
    "# Temperatur: Steuerung der KreativitÃ¤t (0.1 = konservativ, 1.0 = kreativ)
",
    "
",
    "prompt = "Ein Roboter betritt ein Klassenzimmer und"
",
    "result = generator(prompt, max_length=40, num_return_sequences=1, temperature=0.9, top_k=50)
",
    "
",
    "print("ğŸ¨ Mit Sampling-Parametern:")
",
    "print(result[0]['generated_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ§  Reflexion
",
    "- Wie kreativ oder sinnvoll ist der Text?
",
    "- Welche Rolle spielt der Prompt?
",
    "- Welche Probleme kÃ¶nnten bei realen Anwendungen auftreten (z.â€¯B. Bias, Halluzination)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ§© Bonus: Eigene Modelle ausprobieren
",
    "Optional, wenn Zeit & GPU-Ressourcen verfÃ¼gbar sind:
",
    "- `EleutherAI/gpt-neo-125M`
",
    "- `dbmdz/german-gpt2`
",
    "
",
    "```python
",
    "# generator = pipeline("text-generation", model="EleutherAI/gpt-neo-125M")
",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
